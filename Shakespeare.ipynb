{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shakespeare.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnsBDceRhwrT",
        "outputId": "39aefe2a-92bc-453e-8e88-908101134c53"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFw9-WG7iDCq"
      },
      "source": [
        "text = re.sub('\\.', ' <eos>', text)\n",
        "text = re.sub('\\!', ' <eos>', text)\n",
        "text = re.sub('\\?', ' <eos>', text)\n",
        "text = re.sub('\\\\n\\n', ' ', text)\n",
        "text = re.sub('\\\\n', ' ', text)\n",
        "text = re.sub('\\,', '', text)\n",
        "text = re.sub('\\:', ' :', text)\n",
        "text = re.sub('\\;', '', text)\n",
        "text = re.sub('\\--', ' <eos>', text)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytmkcpmXnPSw"
      },
      "source": [
        "text = text.split()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If4abeOdnpA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a62eec22-a090-40c9-bcfc-58e4dc323e0a"
      },
      "source": [
        "text_lower = []\n",
        "for i in text:\n",
        "  i = i.lower()\n",
        "  text_lower.append(i)\n",
        "\n",
        "text_lower"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'before',\n",
              " 'we',\n",
              " 'proceed',\n",
              " 'any',\n",
              " 'further',\n",
              " 'hear',\n",
              " 'me',\n",
              " 'speak',\n",
              " '<eos>',\n",
              " 'all',\n",
              " ':',\n",
              " 'speak',\n",
              " 'speak',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'you',\n",
              " 'are',\n",
              " 'all',\n",
              " 'resolved',\n",
              " 'rather',\n",
              " 'to',\n",
              " 'die',\n",
              " 'than',\n",
              " 'to',\n",
              " 'famish',\n",
              " '<eos>',\n",
              " 'all',\n",
              " ':',\n",
              " 'resolved',\n",
              " '<eos>',\n",
              " 'resolved',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'first',\n",
              " 'you',\n",
              " 'know',\n",
              " 'caius',\n",
              " 'marcius',\n",
              " 'is',\n",
              " 'chief',\n",
              " 'enemy',\n",
              " 'to',\n",
              " 'the',\n",
              " 'people',\n",
              " '<eos>',\n",
              " 'all',\n",
              " ':',\n",
              " 'we',\n",
              " \"know't\",\n",
              " 'we',\n",
              " \"know't\",\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'let',\n",
              " 'us',\n",
              " 'kill',\n",
              " 'him',\n",
              " 'and',\n",
              " \"we'll\",\n",
              " 'have',\n",
              " 'corn',\n",
              " 'at',\n",
              " 'our',\n",
              " 'own',\n",
              " 'price',\n",
              " '<eos>',\n",
              " \"is't\",\n",
              " 'a',\n",
              " 'verdict',\n",
              " '<eos>',\n",
              " 'all',\n",
              " ':',\n",
              " 'no',\n",
              " 'more',\n",
              " 'talking',\n",
              " \"on't\",\n",
              " 'let',\n",
              " 'it',\n",
              " 'be',\n",
              " 'done',\n",
              " ':',\n",
              " 'away',\n",
              " 'away',\n",
              " '<eos>',\n",
              " 'second',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'one',\n",
              " 'word',\n",
              " 'good',\n",
              " 'citizens',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'we',\n",
              " 'are',\n",
              " 'accounted',\n",
              " 'poor',\n",
              " 'citizens',\n",
              " 'the',\n",
              " 'patricians',\n",
              " 'good',\n",
              " '<eos>',\n",
              " 'what',\n",
              " 'authority',\n",
              " 'surfeits',\n",
              " 'on',\n",
              " 'would',\n",
              " 'relieve',\n",
              " 'us',\n",
              " ':',\n",
              " 'if',\n",
              " 'they',\n",
              " 'would',\n",
              " 'yield',\n",
              " 'us',\n",
              " 'but',\n",
              " 'the',\n",
              " 'superfluity',\n",
              " 'while',\n",
              " 'it',\n",
              " 'were',\n",
              " 'wholesome',\n",
              " 'we',\n",
              " 'might',\n",
              " 'guess',\n",
              " 'they',\n",
              " 'relieved',\n",
              " 'us',\n",
              " 'humanely',\n",
              " 'but',\n",
              " 'they',\n",
              " 'think',\n",
              " 'we',\n",
              " 'are',\n",
              " 'too',\n",
              " 'dear',\n",
              " ':',\n",
              " 'the',\n",
              " 'leanness',\n",
              " 'that',\n",
              " 'afflicts',\n",
              " 'us',\n",
              " 'the',\n",
              " 'object',\n",
              " 'of',\n",
              " 'our',\n",
              " 'misery',\n",
              " 'is',\n",
              " 'as',\n",
              " 'an',\n",
              " 'inventory',\n",
              " 'to',\n",
              " 'particularise',\n",
              " 'their',\n",
              " 'abundance',\n",
              " 'our',\n",
              " 'sufferance',\n",
              " 'is',\n",
              " 'a',\n",
              " 'gain',\n",
              " 'to',\n",
              " 'them',\n",
              " 'let',\n",
              " 'us',\n",
              " 'revenge',\n",
              " 'this',\n",
              " 'with',\n",
              " 'our',\n",
              " 'pikes',\n",
              " 'ere',\n",
              " 'we',\n",
              " 'become',\n",
              " 'rakes',\n",
              " ':',\n",
              " 'for',\n",
              " 'the',\n",
              " 'gods',\n",
              " 'know',\n",
              " 'i',\n",
              " 'speak',\n",
              " 'this',\n",
              " 'in',\n",
              " 'hunger',\n",
              " 'for',\n",
              " 'bread',\n",
              " 'not',\n",
              " 'in',\n",
              " 'thirst',\n",
              " 'for',\n",
              " 'revenge',\n",
              " '<eos>',\n",
              " 'second',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'would',\n",
              " 'you',\n",
              " 'proceed',\n",
              " 'especially',\n",
              " 'against',\n",
              " 'caius',\n",
              " 'marcius',\n",
              " '<eos>',\n",
              " 'all',\n",
              " ':',\n",
              " 'against',\n",
              " 'him',\n",
              " 'first',\n",
              " ':',\n",
              " \"he's\",\n",
              " 'a',\n",
              " 'very',\n",
              " 'dog',\n",
              " 'to',\n",
              " 'the',\n",
              " 'commonalty',\n",
              " '<eos>',\n",
              " 'second',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'consider',\n",
              " 'you',\n",
              " 'what',\n",
              " 'services',\n",
              " 'he',\n",
              " 'has',\n",
              " 'done',\n",
              " 'for',\n",
              " 'his',\n",
              " 'country',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'very',\n",
              " 'well',\n",
              " 'and',\n",
              " 'could',\n",
              " 'be',\n",
              " 'content',\n",
              " 'to',\n",
              " 'give',\n",
              " 'him',\n",
              " 'good',\n",
              " 'report',\n",
              " 'fort',\n",
              " 'but',\n",
              " 'that',\n",
              " 'he',\n",
              " 'pays',\n",
              " 'himself',\n",
              " 'with',\n",
              " 'being',\n",
              " 'proud',\n",
              " '<eos>',\n",
              " 'second',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'nay',\n",
              " 'but',\n",
              " 'speak',\n",
              " 'not',\n",
              " 'maliciously',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'i',\n",
              " 'say',\n",
              " 'unto',\n",
              " 'you',\n",
              " 'what',\n",
              " 'he',\n",
              " 'hath',\n",
              " 'done',\n",
              " 'famously',\n",
              " 'he',\n",
              " 'did',\n",
              " 'it',\n",
              " 'to',\n",
              " 'that',\n",
              " 'end',\n",
              " ':',\n",
              " 'though',\n",
              " 'soft-conscienced',\n",
              " 'men',\n",
              " 'can',\n",
              " 'be',\n",
              " 'content',\n",
              " 'to',\n",
              " 'say',\n",
              " 'it',\n",
              " 'was',\n",
              " 'for',\n",
              " 'his',\n",
              " 'country',\n",
              " 'he',\n",
              " 'did',\n",
              " 'it',\n",
              " 'to',\n",
              " 'please',\n",
              " 'his',\n",
              " 'mother',\n",
              " 'and',\n",
              " 'to',\n",
              " 'be',\n",
              " 'partly',\n",
              " 'proud',\n",
              " 'which',\n",
              " 'he',\n",
              " 'is',\n",
              " 'even',\n",
              " 'till',\n",
              " 'the',\n",
              " 'altitude',\n",
              " 'of',\n",
              " 'his',\n",
              " 'virtue',\n",
              " '<eos>',\n",
              " 'second',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'what',\n",
              " 'he',\n",
              " 'cannot',\n",
              " 'help',\n",
              " 'in',\n",
              " 'his',\n",
              " 'nature',\n",
              " 'you',\n",
              " 'account',\n",
              " 'a',\n",
              " 'vice',\n",
              " 'in',\n",
              " 'him',\n",
              " '<eos>',\n",
              " 'you',\n",
              " 'must',\n",
              " 'in',\n",
              " 'no',\n",
              " 'way',\n",
              " 'say',\n",
              " 'he',\n",
              " 'is',\n",
              " 'covetous',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'if',\n",
              " 'i',\n",
              " 'must',\n",
              " 'not',\n",
              " 'i',\n",
              " 'need',\n",
              " 'not',\n",
              " 'be',\n",
              " 'barren',\n",
              " 'of',\n",
              " 'accusations',\n",
              " 'he',\n",
              " 'hath',\n",
              " 'faults',\n",
              " 'with',\n",
              " 'surplus',\n",
              " 'to',\n",
              " 'tire',\n",
              " 'in',\n",
              " 'repetition',\n",
              " '<eos>',\n",
              " 'what',\n",
              " 'shouts',\n",
              " 'are',\n",
              " 'these',\n",
              " '<eos>',\n",
              " 'the',\n",
              " 'other',\n",
              " 'side',\n",
              " \"o'\",\n",
              " 'the',\n",
              " 'city',\n",
              " 'is',\n",
              " 'risen',\n",
              " ':',\n",
              " 'why',\n",
              " 'stay',\n",
              " 'we',\n",
              " 'prating',\n",
              " 'here',\n",
              " '<eos>',\n",
              " 'to',\n",
              " 'the',\n",
              " 'capitol',\n",
              " '<eos>',\n",
              " 'all',\n",
              " ':',\n",
              " 'come',\n",
              " 'come',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'soft',\n",
              " '<eos>',\n",
              " 'who',\n",
              " 'comes',\n",
              " 'here',\n",
              " '<eos>',\n",
              " 'second',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'worthy',\n",
              " 'menenius',\n",
              " 'agrippa',\n",
              " 'one',\n",
              " 'that',\n",
              " 'hath',\n",
              " 'always',\n",
              " 'loved',\n",
              " 'the',\n",
              " 'people',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " \"he's\",\n",
              " 'one',\n",
              " 'honest',\n",
              " 'enough',\n",
              " ':',\n",
              " 'would',\n",
              " 'all',\n",
              " 'the',\n",
              " 'rest',\n",
              " 'were',\n",
              " 'so',\n",
              " '<eos>',\n",
              " 'menenius',\n",
              " ':',\n",
              " 'what',\n",
              " \"work's\",\n",
              " 'my',\n",
              " 'countrymen',\n",
              " 'in',\n",
              " 'hand',\n",
              " '<eos>',\n",
              " 'where',\n",
              " 'go',\n",
              " 'you',\n",
              " 'with',\n",
              " 'bats',\n",
              " 'and',\n",
              " 'clubs',\n",
              " '<eos>',\n",
              " 'the',\n",
              " 'matter',\n",
              " '<eos>',\n",
              " 'speak',\n",
              " 'i',\n",
              " 'pray',\n",
              " 'you',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'our',\n",
              " 'business',\n",
              " 'is',\n",
              " 'not',\n",
              " 'unknown',\n",
              " 'to',\n",
              " 'the',\n",
              " 'senate',\n",
              " 'they',\n",
              " 'have',\n",
              " 'had',\n",
              " 'inkling',\n",
              " 'this',\n",
              " 'fortnight',\n",
              " 'what',\n",
              " 'we',\n",
              " 'intend',\n",
              " 'to',\n",
              " 'do',\n",
              " 'which',\n",
              " 'now',\n",
              " \"we'll\",\n",
              " 'show',\n",
              " \"'em\",\n",
              " 'in',\n",
              " 'deeds',\n",
              " '<eos>',\n",
              " 'they',\n",
              " 'say',\n",
              " 'poor',\n",
              " 'suitors',\n",
              " 'have',\n",
              " 'strong',\n",
              " 'breaths',\n",
              " ':',\n",
              " 'they',\n",
              " 'shall',\n",
              " 'know',\n",
              " 'we',\n",
              " 'have',\n",
              " 'strong',\n",
              " 'arms',\n",
              " 'too',\n",
              " '<eos>',\n",
              " 'menenius',\n",
              " ':',\n",
              " 'why',\n",
              " 'masters',\n",
              " 'my',\n",
              " 'good',\n",
              " 'friends',\n",
              " 'mine',\n",
              " 'honest',\n",
              " 'neighbours',\n",
              " 'will',\n",
              " 'you',\n",
              " 'undo',\n",
              " 'yourselves',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'we',\n",
              " 'cannot',\n",
              " 'sir',\n",
              " 'we',\n",
              " 'are',\n",
              " 'undone',\n",
              " 'already',\n",
              " '<eos>',\n",
              " 'menenius',\n",
              " ':',\n",
              " 'i',\n",
              " 'tell',\n",
              " 'you',\n",
              " 'friends',\n",
              " 'most',\n",
              " 'charitable',\n",
              " 'care',\n",
              " 'have',\n",
              " 'the',\n",
              " 'patricians',\n",
              " 'of',\n",
              " 'you',\n",
              " '<eos>',\n",
              " 'for',\n",
              " 'your',\n",
              " 'wants',\n",
              " 'your',\n",
              " 'suffering',\n",
              " 'in',\n",
              " 'this',\n",
              " 'dearth',\n",
              " 'you',\n",
              " 'may',\n",
              " 'as',\n",
              " 'well',\n",
              " 'strike',\n",
              " 'at',\n",
              " 'the',\n",
              " 'heaven',\n",
              " 'with',\n",
              " 'your',\n",
              " 'staves',\n",
              " 'as',\n",
              " 'lift',\n",
              " 'them',\n",
              " 'against',\n",
              " 'the',\n",
              " 'roman',\n",
              " 'state',\n",
              " 'whose',\n",
              " 'course',\n",
              " 'will',\n",
              " 'on',\n",
              " 'the',\n",
              " 'way',\n",
              " 'it',\n",
              " 'takes',\n",
              " 'cracking',\n",
              " 'ten',\n",
              " 'thousand',\n",
              " 'curbs',\n",
              " 'of',\n",
              " 'more',\n",
              " 'strong',\n",
              " 'link',\n",
              " 'asunder',\n",
              " 'than',\n",
              " 'can',\n",
              " 'ever',\n",
              " 'appear',\n",
              " 'in',\n",
              " 'your',\n",
              " 'impediment',\n",
              " '<eos>',\n",
              " 'for',\n",
              " 'the',\n",
              " 'dearth',\n",
              " 'the',\n",
              " 'gods',\n",
              " 'not',\n",
              " 'the',\n",
              " 'patricians',\n",
              " 'make',\n",
              " 'it',\n",
              " 'and',\n",
              " 'your',\n",
              " 'knees',\n",
              " 'to',\n",
              " 'them',\n",
              " 'not',\n",
              " 'arms',\n",
              " 'must',\n",
              " 'help',\n",
              " '<eos>',\n",
              " 'alack',\n",
              " 'you',\n",
              " 'are',\n",
              " 'transported',\n",
              " 'by',\n",
              " 'calamity',\n",
              " 'thither',\n",
              " 'where',\n",
              " 'more',\n",
              " 'attends',\n",
              " 'you',\n",
              " 'and',\n",
              " 'you',\n",
              " 'slander',\n",
              " 'the',\n",
              " 'helms',\n",
              " \"o'\",\n",
              " 'the',\n",
              " 'state',\n",
              " 'who',\n",
              " 'care',\n",
              " 'for',\n",
              " 'you',\n",
              " 'like',\n",
              " 'fathers',\n",
              " 'when',\n",
              " 'you',\n",
              " 'curse',\n",
              " 'them',\n",
              " 'as',\n",
              " 'enemies',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'care',\n",
              " 'for',\n",
              " 'us',\n",
              " '<eos>',\n",
              " 'true',\n",
              " 'indeed',\n",
              " '<eos>',\n",
              " 'they',\n",
              " \"ne'er\",\n",
              " 'cared',\n",
              " 'for',\n",
              " 'us',\n",
              " 'yet',\n",
              " ':',\n",
              " 'suffer',\n",
              " 'us',\n",
              " 'to',\n",
              " 'famish',\n",
              " 'and',\n",
              " 'their',\n",
              " 'store-houses',\n",
              " 'crammed',\n",
              " 'with',\n",
              " 'grain',\n",
              " 'make',\n",
              " 'edicts',\n",
              " 'for',\n",
              " 'usury',\n",
              " 'to',\n",
              " 'support',\n",
              " 'usurers',\n",
              " 'repeal',\n",
              " 'daily',\n",
              " 'any',\n",
              " 'wholesome',\n",
              " 'act',\n",
              " 'established',\n",
              " 'against',\n",
              " 'the',\n",
              " 'rich',\n",
              " 'and',\n",
              " 'provide',\n",
              " 'more',\n",
              " 'piercing',\n",
              " 'statutes',\n",
              " 'daily',\n",
              " 'to',\n",
              " 'chain',\n",
              " 'up',\n",
              " 'and',\n",
              " 'restrain',\n",
              " 'the',\n",
              " 'poor',\n",
              " '<eos>',\n",
              " 'if',\n",
              " 'the',\n",
              " 'wars',\n",
              " 'eat',\n",
              " 'us',\n",
              " 'not',\n",
              " 'up',\n",
              " 'they',\n",
              " 'will',\n",
              " 'and',\n",
              " \"there's\",\n",
              " 'all',\n",
              " 'the',\n",
              " 'love',\n",
              " 'they',\n",
              " 'bear',\n",
              " 'us',\n",
              " '<eos>',\n",
              " 'menenius',\n",
              " ':',\n",
              " 'either',\n",
              " 'you',\n",
              " 'must',\n",
              " 'confess',\n",
              " 'yourselves',\n",
              " 'wondrous',\n",
              " 'malicious',\n",
              " 'or',\n",
              " 'be',\n",
              " 'accused',\n",
              " 'of',\n",
              " 'folly',\n",
              " '<eos>',\n",
              " 'i',\n",
              " 'shall',\n",
              " 'tell',\n",
              " 'you',\n",
              " 'a',\n",
              " 'pretty',\n",
              " 'tale',\n",
              " ':',\n",
              " 'it',\n",
              " 'may',\n",
              " 'be',\n",
              " 'you',\n",
              " 'have',\n",
              " 'heard',\n",
              " 'it',\n",
              " 'but',\n",
              " 'since',\n",
              " 'it',\n",
              " 'serves',\n",
              " 'my',\n",
              " 'purpose',\n",
              " 'i',\n",
              " 'will',\n",
              " 'venture',\n",
              " 'to',\n",
              " 'stale',\n",
              " \"'t\",\n",
              " 'a',\n",
              " 'little',\n",
              " 'more',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'well',\n",
              " \"i'll\",\n",
              " 'hear',\n",
              " 'it',\n",
              " 'sir',\n",
              " ':',\n",
              " 'yet',\n",
              " 'you',\n",
              " 'must',\n",
              " 'not',\n",
              " 'think',\n",
              " 'to',\n",
              " 'fob',\n",
              " 'off',\n",
              " 'our',\n",
              " 'disgrace',\n",
              " 'with',\n",
              " 'a',\n",
              " 'tale',\n",
              " ':',\n",
              " 'but',\n",
              " 'an',\n",
              " \"'t\",\n",
              " 'please',\n",
              " 'you',\n",
              " 'deliver',\n",
              " '<eos>',\n",
              " 'menenius',\n",
              " ':',\n",
              " 'there',\n",
              " 'was',\n",
              " 'a',\n",
              " 'time',\n",
              " 'when',\n",
              " 'all',\n",
              " 'the',\n",
              " \"body's\",\n",
              " 'members',\n",
              " \"rebell'd\",\n",
              " 'against',\n",
              " 'the',\n",
              " 'belly',\n",
              " 'thus',\n",
              " 'accused',\n",
              " 'it',\n",
              " ':',\n",
              " 'that',\n",
              " 'only',\n",
              " 'like',\n",
              " 'a',\n",
              " 'gulf',\n",
              " 'it',\n",
              " 'did',\n",
              " 'remain',\n",
              " \"i'\",\n",
              " 'the',\n",
              " 'midst',\n",
              " \"o'\",\n",
              " 'the',\n",
              " 'body',\n",
              " 'idle',\n",
              " 'and',\n",
              " 'unactive',\n",
              " 'still',\n",
              " 'cupboarding',\n",
              " 'the',\n",
              " 'viand',\n",
              " 'never',\n",
              " 'bearing',\n",
              " 'like',\n",
              " 'labour',\n",
              " 'with',\n",
              " 'the',\n",
              " 'rest',\n",
              " 'where',\n",
              " 'the',\n",
              " 'other',\n",
              " 'instruments',\n",
              " 'did',\n",
              " 'see',\n",
              " 'and',\n",
              " 'hear',\n",
              " 'devise',\n",
              " 'instruct',\n",
              " 'walk',\n",
              " 'feel',\n",
              " 'and',\n",
              " 'mutually',\n",
              " 'participate',\n",
              " 'did',\n",
              " 'minister',\n",
              " 'unto',\n",
              " 'the',\n",
              " 'appetite',\n",
              " 'and',\n",
              " 'affection',\n",
              " 'common',\n",
              " 'of',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'body',\n",
              " '<eos>',\n",
              " 'the',\n",
              " 'belly',\n",
              " \"answer'd\",\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'well',\n",
              " 'sir',\n",
              " 'what',\n",
              " 'answer',\n",
              " 'made',\n",
              " 'the',\n",
              " 'belly',\n",
              " '<eos>',\n",
              " 'menenius',\n",
              " ':',\n",
              " 'sir',\n",
              " 'i',\n",
              " 'shall',\n",
              " 'tell',\n",
              " 'you',\n",
              " '<eos>',\n",
              " 'with',\n",
              " 'a',\n",
              " 'kind',\n",
              " 'of',\n",
              " 'smile',\n",
              " 'which',\n",
              " \"ne'er\",\n",
              " 'came',\n",
              " 'from',\n",
              " 'the',\n",
              " 'lungs',\n",
              " 'but',\n",
              " 'even',\n",
              " 'thus',\n",
              " '<eos>',\n",
              " 'for',\n",
              " 'look',\n",
              " 'you',\n",
              " 'i',\n",
              " 'may',\n",
              " 'make',\n",
              " 'the',\n",
              " 'belly',\n",
              " 'smile',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'speak',\n",
              " '<eos>it',\n",
              " 'tauntingly',\n",
              " 'replied',\n",
              " 'to',\n",
              " 'the',\n",
              " 'discontented',\n",
              " 'members',\n",
              " 'the',\n",
              " 'mutinous',\n",
              " 'parts',\n",
              " 'that',\n",
              " 'envied',\n",
              " 'his',\n",
              " 'receipt',\n",
              " 'even',\n",
              " 'so',\n",
              " 'most',\n",
              " 'fitly',\n",
              " 'as',\n",
              " 'you',\n",
              " 'malign',\n",
              " 'our',\n",
              " 'senators',\n",
              " 'for',\n",
              " 'that',\n",
              " 'they',\n",
              " 'are',\n",
              " 'not',\n",
              " 'such',\n",
              " 'as',\n",
              " 'you',\n",
              " '<eos>',\n",
              " 'first',\n",
              " 'citizen',\n",
              " ':',\n",
              " 'your',\n",
              " \"belly's\",\n",
              " 'answer',\n",
              " '<eos>',\n",
              " 'what',\n",
              " '<eos>',\n",
              " 'the',\n",
              " 'kingly-crowned',\n",
              " 'head',\n",
              " 'the',\n",
              " 'vigilant',\n",
              " 'eye',\n",
              " 'the',\n",
              " 'counsellor',\n",
              " 'heart',\n",
              " 'the',\n",
              " 'arm',\n",
              " 'our',\n",
              " 'soldier',\n",
              " 'our',\n",
              " 'steed',\n",
              " 'the',\n",
              " 'leg',\n",
              " 'the',\n",
              " 'tongue',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y73nXZMEmo4a"
      },
      "source": [
        "word_counts = {}\n",
        "\n",
        "for i in range(len(text_lower)):\n",
        "  if text_lower[i] in word_counts:\n",
        "    word_counts[text_lower[i]] += 1\n",
        "  else:\n",
        "    word_counts[text_lower[i]] = 1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA0LnWWrohPZ"
      },
      "source": [
        "word_counts_list = []\n",
        "for key in word_counts:\n",
        "  word_counts_list.append((key, word_counts[key]))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5PnqyhIok-U"
      },
      "source": [
        "ordered_list = sorted(word_counts_list, key = lambda word: word[1], reverse=True)\n",
        "print(len(ordered_list))\n",
        "ordered_list = ordered_list[0:5000]\n",
        "ordered_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzaPpHiJolA_",
        "outputId": "07eae772-85b6-4c59-c73c-5ee7d4ad4213"
      },
      "source": [
        "word2idx = {}\n",
        "for i in range(len(ordered_list)):\n",
        "  word2idx[ordered_list[i][0]] = i\n",
        "print(len(word2idx))\n",
        "word2idx['<unk>'] = len(word2idx)\n",
        "print(len(word2idx))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "5001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIusi3hOQcJ6"
      },
      "source": [
        "idx2word = {y:x for x, y in word2idx.items()}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uru38r4Uo74A"
      },
      "source": [
        "text_words = []\n",
        "text_idx = []\n",
        "\n",
        "for word in text_lower:\n",
        "    idx = []\n",
        "    if word in word2idx:\n",
        "      text_words.append(word)\n",
        "      text_idx.append(word2idx[word])\n",
        "    else:\n",
        "      text_words.append('<unk>')\n",
        "      text_idx.append(word2idx['<unk>'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msCbU-3iuwNy"
      },
      "source": [
        "#creates sequences of a certain length\n",
        "\n",
        "seq_length = 32\n",
        "\n",
        "text_words_seq = []\n",
        "text_idx_seq = []\n",
        "\n",
        "for i in range(len(text_words) - seq_length):\n",
        "  seq_wds = ' '.join(text_words[i : i + seq_length])\n",
        "  text_words_seq.append(seq_wds)\n",
        "\n",
        "  seq_idxs = text_idx[i : i + seq_length]\n",
        "  text_idx_seq.append(seq_idxs)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQTwXbYBhJWW",
        "outputId": "d24afef1-99af-4071-a3c1-9e1cbe4ade10"
      },
      "source": [
        "data = torch.tensor(text_idx_seq)\n",
        "\n",
        "# 80 percent train, 10 percent validation, 10 percent test split\n",
        "\n",
        "end1 = round(len(text_words_seq)*.9) # to get 90% for training\n",
        "end2 = round(len(text_words_seq)*.95) # to get 5% for validation and test\n",
        "print(end1)\n",
        "print(end2)\n",
        "\n",
        "train_data = data[0:end1]\n",
        "val_data = data[end1:end2]\n",
        "test_data = data[end2:]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "203306\n",
            "214601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAIy4VCkygt2"
      },
      "source": [
        "class twoLayer_LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, layers):\n",
        "        super().__init__()\n",
        "        self.emb_layer = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.rec_layer = nn.LSTM(hidden_size, hidden_size, num_layers=layers)\n",
        "        self.lin_layer = nn.Linear(hidden_size, vocab_size)\n",
        "        # if want to make bi directional\n",
        "        #self.rec_layer = nn.LSTM(hidden_size, hidden_size, num_layers=layers, bidirectional=True)\n",
        "        #self.lin_layer = nn.Linear(hidden_size*2, vocab_size)\n",
        "\n",
        "    def forward(self, word_seq, h_init, c_init):\n",
        "        g_seq = self.emb_layer(word_seq)  \n",
        "        h_seq, (h_last, c_last) = self.rec_layer(g_seq, (h_init, c_init))\n",
        "        score_seq = self.lin_layer(h_seq)\n",
        "        return score_seq, (h_last, c_last)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEXgFadZykiv"
      },
      "source": [
        "def evaluate(data):\n",
        "    running_loss = 0\n",
        "    num_batches = 0    \n",
        "    with torch.no_grad():\n",
        "        h = torch.zeros(layers, bs, hidden_size)\n",
        "        c = torch.zeros(layers, bs, hidden_size)\n",
        "        h = h.to(device)\n",
        "        c = c.to(device)\n",
        "        for count in range(0, len(data) - bs, bs):\n",
        "            minibatch_data = data.long()[count:count + bs]\n",
        "            minibatch_label = data.long()[count+1:count + bs + 1]\n",
        "            minibatch_data = minibatch_data.to(device)\n",
        "            minibatch_label = minibatch_label.to(device)\n",
        "            scores, (h, c) = net(minibatch_data, h, c)\n",
        "            minibatch_label = minibatch_label.view(bs * seq_length) \n",
        "            scores = scores.view(bs * seq_length, vocab_size)\n",
        "            loss = criterion(scores, minibatch_label)    \n",
        "            h = h.detach()\n",
        "            c = c.detach()\n",
        "            num_batches += 1  \n",
        "    return loss.item()\n",
        "\n",
        "def normalize_gradient(net):\n",
        "    grad_norm_sq = 0\n",
        "    for p in net.parameters():\n",
        "        grad_norm_sq += p.grad.data.norm()**2\n",
        "    grad_norm = math.sqrt(grad_norm_sq)\n",
        "    if grad_norm < 1e-4:\n",
        "        net.zero_grad()\n",
        "        print('grad norm close to zero')\n",
        "    else:    \n",
        "        for p in net.parameters():\n",
        "             p.grad.data.div_(grad_norm)\n",
        "    return grad_norm"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iWhgMqlytzZ"
      },
      "source": [
        "# setup NN\n",
        "hidden_size = 100\n",
        "vocab_size = len(word2idx)+1\n",
        "layers = 3\n",
        "num_epoch = 8\n",
        "bs = 32\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "net = twoLayer_LSTM(vocab_size, hidden_size, layers)\n",
        "net.emb_layer.weight.data.uniform_(-0.1, 0.1)\n",
        "net.lin_layer.weight = net.emb_layer.weight\n",
        "net = net.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "train_size = len(train_data)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw6hIHGfyuv0",
        "outputId": "2dceca97-a3ee-44bb-d2cc-e4a1ff3494e8"
      },
      "source": [
        "# training with SGD\n",
        "start = time.time()\n",
        "\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "test_loss_list = []\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    #if epoch > 0:\n",
        "    my_lr = 1.5 * math.exp(-0.5 * epoch)\n",
        "    optimizer = optim.SGD(net.parameters(), lr=my_lr, momentum=0.9)\n",
        "            \n",
        "    # set the running quantities to zero at the beginning of the epoch\n",
        "    running_loss = 0\n",
        "    num_batches = 0    \n",
        "       \n",
        "    # set the initial h to be the zero vector\n",
        "    h = torch.zeros(layers, bs, hidden_size)\n",
        "    c = torch.zeros(layers, bs, hidden_size)\n",
        "    # send it to the gpu    \n",
        "    h = h.to(device)\n",
        "    c = c.to(device)\n",
        "\n",
        "    for count in range(0, train_size - bs, bs):    \n",
        "        # Set the gradients to zeros\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # create a minibatch\n",
        "        minibatch_data = train_data.long()[count : count + bs]\n",
        "        minibatch_label = train_data.long()[count + 1 : count + bs + 1]\n",
        "                \n",
        "        # send them to the gpu\n",
        "        minibatch_data = minibatch_data.to(device)\n",
        "        minibatch_label = minibatch_label.to(device)\n",
        "        \n",
        "        # Detach to prevent from backpropagating all the way to the beginning\n",
        "        # Then tell Pytorch to start tracking all operations that will be done on h and c\n",
        "        h = h.detach()\n",
        "        c = c.detach()\n",
        "        h = h.requires_grad_()\n",
        "        c = c.requires_grad_()\n",
        "        # forward the minibatch through the net \n",
        "        scores, (h, c) = net(minibatch_data, h, c)\n",
        "        # reshape the scores and labels to huge batch of size bs*seq_length\n",
        "        scores = scores.view(bs * seq_length, vocab_size)  \n",
        "        minibatch_label = minibatch_label.view(bs * seq_length)       \n",
        "        \n",
        "        # Compute the average of the losses of the data points in this huge batch\n",
        "        loss = criterion(scores, minibatch_label)\n",
        "        \n",
        "        # backward pass to compute dL/dR, dL/dV and dL/dW\n",
        "        loss.backward()\n",
        "\n",
        "        # do one step of stochastic gradient descent: R=R-lr(dL/dR), V=V-lr(dL/dV), ...\n",
        "        normalize_gradient(net)\n",
        "        optimizer.step()\n",
        "        \n",
        "        # update the running loss  \n",
        "        #running_loss += loss.item()\n",
        "        num_batches += 1\n",
        "                          \n",
        "    #total_loss = running_loss/num_batches\n",
        "    elapsed = time.time() - start\n",
        "    print('\\nepoch =', epoch, '\\t time = {0:.1f}'.format(elapsed),'\\t lr = {0:.3f}'.format(my_lr), '\\t training loss = {0:.3f}'.format(loss.item())) # compute error on the test set at end of each epoch\n",
        "    val_loss = evaluate(val_data) # eval on the validation set\n",
        "    train_loss_list.append(loss.item())\n",
        "    val_loss_list.append(val_loss)\n",
        "    test_loss = evaluate(test_data) # eval on the test set\n",
        "    test_loss_list.append(test_loss)\n",
        "    print('val loss = {0:.3f}'.format(val_loss))\n",
        "    print('test loss = {0:.3f}'.format(test_loss))\n",
        "\n",
        "print(\" \")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 0 \t time = 47.6 \t lr = 1.500 \t training loss = 6.178\n",
            "val loss = 7.713\n",
            "test loss = 7.479\n",
            "\n",
            "epoch = 1 \t time = 97.0 \t lr = 0.910 \t training loss = 5.857\n",
            "val loss = 7.014\n",
            "test loss = 6.974\n",
            "\n",
            "epoch = 2 \t time = 146.6 \t lr = 0.552 \t training loss = 5.887\n",
            "val loss = 6.724\n",
            "test loss = 6.642\n",
            "\n",
            "epoch = 3 \t time = 196.0 \t lr = 0.335 \t training loss = 5.891\n",
            "val loss = 6.429\n",
            "test loss = 6.382\n",
            "\n",
            "epoch = 4 \t time = 245.8 \t lr = 0.203 \t training loss = 5.867\n",
            "val loss = 6.384\n",
            "test loss = 6.395\n",
            "\n",
            "epoch = 5 \t time = 295.1 \t lr = 0.123 \t training loss = 5.611\n",
            "val loss = 6.321\n",
            "test loss = 6.291\n",
            "\n",
            "epoch = 6 \t time = 344.4 \t lr = 0.075 \t training loss = 5.305\n",
            "val loss = 6.177\n",
            "test loss = 6.324\n",
            "\n",
            "epoch = 7 \t time = 394.4 \t lr = 0.045 \t training loss = 5.393\n",
            "val loss = 6.077\n",
            "test loss = 6.166\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBE_wJ1b91ya",
        "outputId": "206ddcd6-a10d-4fd5-d0f8-246feebd2cab"
      },
      "source": [
        "# training with Adagrad\n",
        "start = time.time()\n",
        "\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "test_loss_list = []\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    #if epoch > 0:\n",
        "    my_lr = 0.1 * math.exp(-0.5 * epoch)\n",
        "    optimizer = optim.Adagrad(net.parameters(), lr=my_lr)\n",
        "            \n",
        "    # set the running quantities to zero at the beginning of the epoch\n",
        "    running_loss = 0\n",
        "    num_batches = 0    \n",
        "       \n",
        "    # set the initial h to be the zero vector\n",
        "    h = torch.zeros(layers, bs, hidden_size)\n",
        "    c = torch.zeros(layers, bs, hidden_size)\n",
        "    # send it to the gpu    \n",
        "    h = h.to(device)\n",
        "    c = c.to(device)\n",
        "\n",
        "    for count in range(0, train_size - bs, bs):    \n",
        "        # Set the gradients to zeros\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # create a minibatch\n",
        "        minibatch_data = train_data.long()[count : count + bs]\n",
        "        minibatch_label = train_data.long()[count + 1 : count + bs + 1]        \n",
        "                \n",
        "        # send them to the gpu\n",
        "        minibatch_data = minibatch_data.to(device)\n",
        "        minibatch_label = minibatch_label.to(device)\n",
        "        \n",
        "        # Detach to prevent from backpropagating all the way to the beginning\n",
        "        # Then tell Pytorch to start tracking all operations that will be done on h and c\n",
        "        h = h.detach()\n",
        "        c = c.detach()\n",
        "        h = h.requires_grad_()\n",
        "        c = c.requires_grad_()\n",
        "        # forward the minibatch through the net \n",
        "        scores, (h, c) = net(minibatch_data, h, c)\n",
        "        # reshape the scores and labels to huge batch of size bs*seq_length\n",
        "        scores = scores.view(bs * seq_length, vocab_size)  \n",
        "        minibatch_label = minibatch_label.view(bs * seq_length)       \n",
        "        \n",
        "        # Compute the average of the losses of the data points in this huge batch\n",
        "        loss = criterion(scores, minibatch_label)\n",
        "        \n",
        "        # backward pass to compute dL/dR, dL/dV and dL/dW\n",
        "        loss.backward()\n",
        "\n",
        "        # do one step of stochastic gradient descent: R=R-lr(dL/dR), V=V-lr(dL/dV), ...\n",
        "        normalize_gradient(net)\n",
        "        optimizer.step()\n",
        "        \n",
        "        # update the running loss  \n",
        "        #running_loss += loss.item()\n",
        "        num_batches += 1\n",
        "                          \n",
        "    #total_loss = running_loss/num_batches\n",
        "    elapsed = time.time() - start\n",
        "    print('\\nepoch =', epoch, '\\t time = {0:.1f}'.format(elapsed),'\\t lr = {0:.3f}'.format(my_lr), '\\t training loss = {0:.3f}'.format(loss.item())) # compute error on the test set at end of each epoch\n",
        "    val_loss = evaluate(val_data) # eval on the validation set\n",
        "    train_loss_list.append(loss.item())\n",
        "    val_loss_list.append(val_loss)\n",
        "    test_loss = evaluate(test_data) # eval on the test set\n",
        "    test_loss_list.append(test_loss)\n",
        "    print('val loss = {0:.3f}'.format(val_loss))\n",
        "    print('test loss = {0:.3f}'.format(test_loss))\n",
        "\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 0 \t time = 84.2 \t lr = 0.100 \t training loss = 4.541\n",
            "val loss = 5.423\n",
            "test loss = 5.368\n",
            "\n",
            "epoch = 1 \t time = 169.9 \t lr = 0.061 \t training loss = 4.569\n",
            "val loss = 5.524\n",
            "test loss = 5.411\n",
            "\n",
            "epoch = 2 \t time = 254.4 \t lr = 0.037 \t training loss = 4.453\n",
            "val loss = 5.427\n",
            "test loss = 5.368\n",
            "\n",
            "epoch = 3 \t time = 338.4 \t lr = 0.022 \t training loss = 4.485\n",
            "val loss = 5.482\n",
            "test loss = 5.462\n",
            "\n",
            "epoch = 4 \t time = 422.5 \t lr = 0.014 \t training loss = 4.469\n",
            "val loss = 5.476\n",
            "test loss = 5.495\n",
            "\n",
            "epoch = 5 \t time = 506.2 \t lr = 0.008 \t training loss = 4.473\n",
            "val loss = 5.533\n",
            "test loss = 5.527\n",
            "\n",
            "epoch = 6 \t time = 590.4 \t lr = 0.005 \t training loss = 4.464\n",
            "val loss = 5.539\n",
            "test loss = 5.503\n",
            "\n",
            "epoch = 7 \t time = 675.8 \t lr = 0.003 \t training loss = 4.480\n",
            "val loss = 5.525\n",
            "test loss = 5.469\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "D1XRnGHiyuzB",
        "outputId": "55d5d714-a1d3-4d0d-e94d-dd5555650cc5"
      },
      "source": [
        "x = range(0, num_epoch,1)\n",
        "\n",
        "plt.plot(x, train_loss_list, '.-', label='Train Loss')\n",
        "plt.plot(x, val_loss_list, '.-', label='Val Loss')\n",
        "plt.plot(x, test_loss_list, '.-', label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHrChCwtzged"
      },
      "source": [
        "def show_most_likely_words(prob):\n",
        "    num_word_display = 15\n",
        "    p = prob.view(-1)\n",
        "    p, word_idx = torch.topk(p, num_word_display)\n",
        "    for i, idx in enumerate(word_idx):\n",
        "        percentage = p[i].item() * 100\n",
        "        word = idx2word[idx.item()]\n",
        "        print(\"{:.1f}%\\t\".format(percentage), word) \n",
        "\n",
        "def text2tensor(text):\n",
        "    text = text.lower()\n",
        "    list_of_words = text.split()\n",
        "    list_of_idx = []\n",
        "    for w in list_of_words:\n",
        "      if w in word2idx:\n",
        "        idx = word2idx[w]\n",
        "        list_of_idx.append(idx)\n",
        "      else:\n",
        "        list_of_idx.append(len(word2idx)-1)\n",
        "    x = torch.LongTensor(list_of_idx)\n",
        "    return x"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rIAEWmomVeFO",
        "outputId": "57510037-e179-4999-ac9e-b112c77e0ce2"
      },
      "source": [
        "' '.join(text_words_seq[100].split()[0:10])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<eos> first citizen : we are accounted poor citizens the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVSZHX7mzmAl",
        "outputId": "f713b494-d768-4da3-87fd-f8a3db64fbae"
      },
      "source": [
        "print(text_words_seq[100])\n",
        "sentence = ' '.join(text_words_seq[100].split()[0:13])\n",
        "\n",
        "h = torch.zeros(layers, bs, hidden_size)\n",
        "c = torch.zeros(layers, bs, hidden_size)\n",
        "h = h.to(device)\n",
        "c = c.to(device)\n",
        "\n",
        "data = text2tensor(sentence)\n",
        "seq_len = len(data)\n",
        "data = data.view(seq_len, -1)\n",
        "empty = torch.zeros(seq_len, bs - 1).type(torch.LongTensor)\n",
        "data = torch.cat((data, empty), dim=1)\n",
        "data = data.to(device)\n",
        "scores, (h, c) = net(data, h, c)\n",
        "scores = scores[seq_len - 1, 0, :]\n",
        "p = F.softmax(scores.view(1, vocab_size), dim=1)\n",
        "print(sentence, '... \\n')\n",
        "show_most_likely_words(p)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<eos> first citizen : we are accounted poor citizens the patricians good <eos> what authority surfeits on would relieve us : if they would yield us but the superfluity while it were\n",
            "<eos> first citizen : we are accounted poor citizens the patricians good <eos> ... \n",
            "\n",
            "6.0%\t hortensio\n",
            "5.2%\t tranio\n",
            "5.0%\t i\n",
            "4.3%\t gremio\n",
            "4.0%\t petruchio\n",
            "2.0%\t what\n",
            "1.8%\t you\n",
            "1.6%\t first\n",
            "1.5%\t if\n",
            "1.4%\t but\n",
            "1.4%\t o\n",
            "1.2%\t for\n",
            "1.2%\t sly\n",
            "1.2%\t lucio\n",
            "1.2%\t and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDHlWDDIzq-A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}